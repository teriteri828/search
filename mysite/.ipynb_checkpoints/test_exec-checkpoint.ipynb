{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "black_proc = subprocess.run(['black', './search/views'], capture_output=True)\n",
    "black_proc = subprocess.run(['black', './search/tests'], capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System check identified no issues (0 silenced).\n",
      "ret\n",
      "[MorphologicalBackDataWords(data_id=100, words=['私 人間'])]\n",
      "ret\n",
      "[MorphologicalBackDataWords(data_id=100, words=['私 人間']), MorphologicalBackDataWords(data_id=1, words=['私 車 好き'])]\n",
      "aaa\n",
      "SearchCountVectorEntity(vector=array([0, 1, 1, 0, 0]))\n",
      "ret\n",
      "[MorphologicalBackDataWords(data_id=1, words=['私 人間 好き'])]\n",
      "ret\n",
      "[MorphologicalBackDataWords(data_id=1, words=['私 人間 好き']), MorphologicalBackDataWords(data_id=2, words=['私 車 好き'])]\n",
      "ret\n",
      "[MorphologicalBackDataWords(data_id=1, words=['私 人間 好き']), MorphologicalBackDataWords(data_id=2, words=['私 車 好き']), MorphologicalBackDataWords(data_id=3, words=['君 猫 好き'])]\n",
      "[BackDataCountVectorEntity(data_id=1, vector=array([0, 1, 1, 0, 0])), BackDataCountVectorEntity(data_id=2, vector=array([0, 0, 1, 0, 0])), BackDataCountVectorEntity(data_id=3, vector=array([0, 0, 1, 0, 0]))]\n",
      "####################\n",
      "1\n",
      "0.9999999999999998\n",
      "####################\n",
      "2\n",
      "0.7071067811865475\n",
      "####################\n",
      "3\n",
      "0.7071067811865475\n",
      "\n",
      "Creating test database for alias 'default'...\n",
      "..s....F.......\n",
      "======================================================================\n",
      "FAIL: test_検索クエリとバックデータのベクトルを基に類似度を計算しバックデータを類似度の降順にし返却する (search.tests.test_search_service_application.TestSearchSeviceApplication)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tomoya/django_work/mysite/search/tests/test_search_service_application.py\", line 113, in test_検索クエリとバックデータのベクトルを基に類似度を計算しバックデータを類似度の降順にし返却する\n",
      "    self.assertEqual(actual, expect)\n",
      "AssertionError: SeekD[29 chars]a_id=1, uid='44765', title='私は人間が好きです', catego[411 chars]75)]) != SeekD[29 chars]a_id=3, uid='44765', title='私は猫が好きです', categor[408 chars]89)])\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 15 tests in 19.127s\n",
      "\n",
      "FAILED (failures=1, skipped=1)\n",
      "Destroying test database for alias 'default'...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "test_python_proc = subprocess.run(['python', 'manage.py', 'test', 'search'], capture_output=True)\n",
    "# proc.stdoutはバイナリなので decode してやると文字列に変換できる\n",
    "print(test_python_proc.stdout.decode('utf-8'))\n",
    "print(test_python_proc.stderr.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[0 1 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]]\n",
      "\n",
      "loaded_model\n",
      "[[0 1 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]]\n",
      "\n",
      "test\n",
      "[[0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "# ベクトル化する文字列\n",
    "sample = np.array([\n",
    "                    '私 人間 好き', \n",
    "                    '私 車 好き', \n",
    "                    '私 猫 好き', \n",
    "                    '君 人間', \n",
    "                    '君 車 好き', \n",
    "                    '君 猫 好き', \n",
    "                    '猫 魚 鉱物', \n",
    "                    '車 乗る 物', \n",
    "                    '猫 走る',\n",
    "                    '車 乗る',\n",
    "                  ])\n",
    "\n",
    "# CountVectorizer\n",
    "vec_count = CountVectorizer(min_df=1)\n",
    "\n",
    "# ベクトル化\n",
    "vec_count.fit(sample)\n",
    "print(\"X\")\n",
    "X = vec_count.transform(sample)\n",
    "\n",
    "print(X.toarray())\n",
    "#type(X.toarray())\n",
    "pkl_vectorizer_path = \"/home/tomoya/django_work/mysite/search/static/ai_model/count_vector/stab.model\"\n",
    "\n",
    "with open(pkl_vectorizer_path, 'wb') as f:\n",
    "        pickle.dump(vec_count, f)\n",
    "        \n",
    "loaded_model = pickle.load(open(pkl_vectorizer_path, 'rb'))\n",
    "print(\"\")\n",
    "print(\"loaded_model\")\n",
    "print(loaded_model.transform(sample).toarray())\n",
    "test = ['僕 お前 これ ドライスーツ 私たち 強く 他者 人として 人たち 地球 バイク 自転車 クルマ 自家用車 車両']\n",
    "test = ['私 車 好き']\n",
    "print(\"\")\n",
    "print(\"test\")\n",
    "print(loaded_model.transform(test).toarray())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
